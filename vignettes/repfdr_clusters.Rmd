---
title: "Algorithm for computing replicability over independent clusters of studies"
author: "Barak Brill, Daniel Yekutieli, Ruth Heller"
date: "2017-02-14"
output: html_document

---

<style type="text/css">
.table {

    width: 75%;

}

th {
  background-color: #000000;
 color: #ffffff;
}

table tr:nth-child(odd) td{
   background-color: #c9d3e2;
}
table tr:nth-child(even) td{
    background-color: #eaedf2;
}
</style>
```{r setup, include=FALSE}
library(knitr) 
#knitr::opts_chunk$set(echo = TRUE)
```

We describe the algorithm for the case nr.association=3 (Allowing both positive and negative dependence of SNP to an outcome). For the nr.association=2 case (Z Scores or SNPs are either null or non null), the implementation is straightforward, given the algorithm below.

Let $bin_{c,i} (j)$ be the bin number of the jth SNP, in the ith study of the cth cluster. The number of studies in the c cluster will be $N_c$. The number of clusters will be $C$. The total number of studies will be $N = \sum_{i=1}^{C} N_i$

Let $\hat{f}_{-1,c,i} (b),\hat{f}_{0,c,i} (b),\hat{f}_{1,c,i} (b)$ be the discretized density estimations, for the ith study in the cth cluster, for the null, positive association and negative association hypothesis. The argument b represents the density of the bth cell in the partition of the Z axis.

Both $bin_{c,i} (j)$ and $\hat{f}_{-1,c,i} (b),\hat{f}_{0,c,i} (b),\hat{f}_{1,c,i} (b)$ are given by the function 'ztobins'.

$\hat{f}_{0,c,i} (bin_{c,i} (j))$ is therefore the probability estimate for the bin of the jth snp in the appropriate study and cluster, under the null. Similarly we have $\hat{f}_{1,c,i} (bin_{c,i} (j))$ and $\hat{f}_{-1,c,i} (bin_{c,i} (j))$

The outcome of the RepFdr procedure inside cluster $c$, is a matrix of the form:

<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:center; vertical-align: text-top; padding:0px 0px; ; text-size:9px; color:#2566ce">
  Table 1: An illustration of all possible hypotheses states for Nc studies, as well as    their denoted probability. The sum of the probabilities is 1
</div>
<center>
| Study 1  |  Study 2 | ... | Study $N_c$ | $\pi$ |
|:------:|:-----:|:------:|:------:|:------:|
| 0 | 0 | 0 over remaining in row | 0 | $\pi_{(0,0,‚Ä¶,0)}$ |
| 1 | 0 | 0 over remaining cols in row | 0 | $\pi_{(1,0,‚Ä¶,0)}$ |
| -1 | 0 | 0 over remaining in row | 0 | $\pi_{(-1,0,‚Ä¶,0)}$ |
| ... | ... | ...| ... | ... |
| -1 | -1 | -1 over remaining in row | 0 | $\pi_{(-1,0,‚Ä¶,0)}$ |
</center>


This table has $3^{N_{c}}$ rows (or $2^{N_{c}}$ for the nr.association=2 case)

We now perform an aggregation using the above table, for the computation of the Local FDR for the jth SNP. The aggregation is to a table of the form:
<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:center; vertical-align: text-top; padding:0px 0px; ; text-size:9px; color:#2566ce">
Table 2: All possible hypotheses states  combinations so that exactly k are -1, l are 0, and m are 1, for the $N_c$ studies, as well as their denoted local fdr for feature j. 
</div>
<center>
| Study 1  |  Study 2 | ... | Study N_c |
|------|-----|------|------|
| $N_c$ | $0$ | $0$ | $lfdr_{(N_c,0,0)}^{(c)} (j)$ |
| $N_c-1$ | $1$ | $0$  | $lfdr_{N_c-1,1,0}^{(c)} (j)$ |
| $N_c-2$ | $1$ | $1$ | $lfdr_{N_c-2,1,1}^{(c)} (j)$ |
| ... | ... | ...| ... |
| $0$ | $0$ | $N_c$ | $lfdr_{0,0,N_c}^{(c)} (j)$ |
</center>


With the rows being a coarser partition of the prior œÄ .The first three columns give the partition of  œÄ to the total number of studies which are positive non null, null or negative non null. The last column gives the aggregated probability for the coarser partition (the local fdr, per cluster, for all hypotheses having this number of positive non nulls, negative non nulls and nulls, no matter which are which).

Let $G_{k,l,m}$ be the set of all vectors of size $N_c$ composed of exactly $k$ entries being -1,$l$ entries being 0, $m$ entries being 1. Let $u_i$ be the state for the ith study (i.e., $u_i \in {-1,0,1}$) of the vector $\hat{u}=(u_1,‚Ä¶,u_{N_{c}} )\in G_{k,l,m}$

The probability that feature $j$ has exactly $k$ hypotheses states -1, $l$ hypotheses states 0, and $m$ hypotheses states 1 among the $N_c$ studies in cluster $c$, given the binned z-scores $bin_{c,1} (j),‚Ä¶,bin_{c,N_c } (j)$, is estimated to be: 

$$ lfdr^{c}_{k,l,m}(j) = \sum_{\vec{u} \in G_{k,l,m}}^{N_c}[\pi_{\vec{u}} \centerdot \prod_{i=1}^{N_c}\hat{f}_{u_i,c,i}(bin_{c,i}(j))] $$

Table 2 has ${N_c + 2 \choose 2}$ rows (splitting $N_c$ indistinct balls into three bins).
The equivalent table for the nr.association=2 case, has  ${N_c + 1 \choose 1} = N_c + 1$ rows (splitting $N_c$ indistinct balls into two bins).

All the local fdrs in the last column of Table 2  can be computed by a single pass on the RepFdr $\pi$ matrix in Table 1 since each of the rows of Table 1 belongs to a single row in Table 2, and all the vectors belonging to a row in Table 2 are in Table 1: one allocates the matrix (for all k,l,m entries) for $lfdr^{(c)}$  , and aggregates the probabilities $\pi_{\vec{u}} \centerdot \prod_{i=1}^{N_c}\hat{f}_{u_i,c,i}(bin_{c,i}(j))$ for the  rows of Table 1 to their appropriate cells in the $lfdr^{(c)}$ùëôùëìùëëùëüùëê Table 2. Table 2 for the jth feature in cluster c will be denoted by $LFDR^{(c)}(j)$.

The per cluster $LFDR^{(c)}(j)$  tables are combined, by an outer product, multiplying the lfdr probabilities of different clusters:
The $LFDR$ table (no c superscript, this is for aggregation over clusters):

<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:center; vertical-align: text-top; padding:0px 0px; ; text-size:9px; color:#2566ce">
Table 3:All possible hypotheses states  combinations so that exacktly k are -1, l are 0, and m are 1, for the N studies, as well as their denoted local fdr, for feature j.
</div>

<center>
| # Studies:-1  |  # Studies:0 | # Studies:1 | $lfdr$ |
|------|-----|------|------|
| N | 0 | 0 | $lfdr_{N_c,0,0}^{(c)}$ |
| N - 1 | 1 | 0  | $lfdr_{N_c-1,1,0}^{(c)}$ |
| N - 2 | 1 | 1 | $lfdr_{N_c-2,1,1}^{(c)}$|
| ... | ... | ...| ... |
| 0 | 0 | N | $lfdr_{0,0,N_c}^{(c)}$|
</center>
  
  The table is computed by an iterative algorithm, described as follows.
For simplicity of notation, we define the operator $M(T^{(1)},T^{(2)})$ which combines two tables, e.g.,   $T^{(1)}=LFDR^{(c_1 )} (j)$ and $T^{(2)}=LFDR^{(c_2 )} (j)$. The definition of M is given in algorithm form, rather than equation.

We will denote by $T_{k_1,-1}^{(1)}$ the Table entry in the $k_1$ th row and first column, i.e.,  the number of studies with hypothesis state -1. Similarly, $T_{k_1,0}^{(1) }$ and $T_{k_1,1}^{(1)}$ are the entries in the second and third columns, respectively, of the $k_1$ th row. 

The probability that feature $j$ has exactly $k=T_{k_1,-1}^{(1)}$ hypotheses states -1, $l=T_{k_1,0}^{(1)}$ hypotheses states 0, and $m=T_{k_1,1}^{(1)}$ hypotheses states 1 among the studies from which $T^{(1)}$ is composed, is denoted by $T_{k_1,lfdr}^{(1) }=lfdr_{k,l,m}^{(1)} (j)$.

 <div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 30px;">
 **Algorithm for computing $M(T^{(1)},T^{(2)})$**
 </div>
 <div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 60px;">
 Generate new lfdr table with no rows, named $T^{(3)}$.
 
 For $k_{1}=1$ to $nr.rows(T^{(1)}$):
</div>
<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 90px;">
 For $k_{2}=1$ to $nr.rows(T^{(2)}$):
</div>
<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 120px;">

$c_{-1}‚ÜêT_{k_1,-1}^{(1)}+T_{k_2,-1}^{(2)}$  
	
$c_0‚ÜêT_{k_1,0}^{(1)}+T_{k_2,0}^{(2)}$
	
$c_1‚ÜêT_{k_1,1}^{(1)}+T_{k_2,1}^{(2)}$
	
if $T^{(3)}$ has a $k_3$ such that $(T_{k_3,-1}^{(3)},T_{k_3,0}^{(3)},T_{k_3,1}^{(3) })=(c_{-1},c_0,c_1)$
</div>
<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 150px;">
$T_{{k_3},lfdr}^{(3)}‚ÜêT_{{k_3},lfdr}^{(3)}+ T_{k_1,lfdr}^{(1)}\centerdot‚ãÖT_{k_2,lfdr}^{(2)}$
</div>
<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 120px;">
else
</div>
<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 150px;">
$k_{new} ‚Üê nr.rows(T^{(3)}) + 1$

$T_{k_{new},-1}^{(3)},T_{k_{new},0}^{(3)},T_{k_{new},1}^{(3)}‚Üê(c_{-1},c_0,c_1)$

$T_{k_{new},lfdr}^{(3)}‚ÜêT_{k_1,lfdr}^{(1)} \centerdot T_{k_2,lfdr}^{(2)}$

</div>
<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 60px;">
Return $T^{(3)}$
</div>

 
 In practice, it is best to implement lfdr tables with preallocated space and an indexing function from $(c_{-1},c_0,c_1)$ to a row number. Another option is the use of a "hashmap " (in our package, implementation is with a standard "hashmap" from STL).
Using the operator $M(T^{(1)},T^{(2)})$, the procedure of computing LFDR is written as:

<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 60px;">
**Algorithm for computing $LFDR(j)$ over all clusters**
</div>

<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 90px;">
$LFDR(j)‚ÜêM(LFDR^{(1)} (j),LFDR^{(2)} (j))$

for $i=3$ to $C$:

</div>
<div style="background-color:rgba(255, 255, 255, 0.0470588); text-align:left; vertical-align: text-top; padding:0px 120px;">
$LFDR(j)‚ÜêM(LFDR(j),LFDR^{(i)} (j))$

 </div>

This is the core of the iterative algorithm, breaking down the computation of the lfdr to iterative executions of the same operator. 